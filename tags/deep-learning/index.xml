<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | </title>
    <link>https://Likhitha96.github.io/tags/deep-learning/</link>
      <atom:link href="https://Likhitha96.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 01 Oct 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://Likhitha96.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Deep Learning</title>
      <link>https://Likhitha96.github.io/tags/deep-learning/</link>
    </image>
    
    <item>
      <title>Vision and Language Navigation</title>
      <link>https://Likhitha96.github.io/project/project1/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://Likhitha96.github.io/project/project1/</guid>
      <description>&lt;p&gt;Mutimodal learning has gained importance with the plethora of data being available through different modes.
One such problem in this field is Vision and Language Navigation.
In this project, we developed a framework in which an agent navigates through a path from a given starting point by following the natural language instructions provided in an indoor house setting.
Each subsequent point location in the path was perceived by the agent as a 360Â° image of what a human eye sees by standing on that location.&lt;/p&gt;

&lt;p&gt;In order to solve this problem, we leveraged both the natural language instructions and the images at each location to output navigation directions at each location and hence finally reaching the intended destination.
The framework makes use of dynamic memory networks and reinforcement learning.&lt;/p&gt;

&lt;p&gt;Technical tools: Pytorch&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi Object Style Transfer</title>
      <link>https://Likhitha96.github.io/project/project5/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>https://Likhitha96.github.io/project/project5/</guid>
      <description>&lt;p&gt;Style transfer is a technique of applying the style of another image on a base image called as the content image in our project. The main focus in our project was on doing style transfer for indoor house objects.
Given a content image of an indoor setting containing an object like a sofa and style image of another sofa design that we want, the goal was to apply the style to the content image without changing the other objects or background.&lt;/p&gt;

&lt;p&gt;We have explored different techniques like segmentation, GANs to develop this framework&lt;/p&gt;

&lt;p&gt;Technical tools: Python, Tensorflow&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving Clinical Decision Making through VQA</title>
      <link>https://Likhitha96.github.io/project/project4/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://Likhitha96.github.io/project/project4/</guid>
      <description>&lt;p&gt;Visual question answering(VQA) involves building a system that takes an image and a question as input and generates the answer as an output.
We have worked on VQA-Med dataset in this project.&lt;/p&gt;

&lt;p&gt;Technical Tools: Tensorflow&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
